nohup: 忽略输入
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:07,  2.42s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.59s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:07<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.06s/it]
Processing files:   0%|          | 0/1 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
Processing files: 100%|██████████| 1/1 [10:26<00:00, 626.82s/it]Processing files: 100%|██████████| 1/1 [10:26<00:00, 626.82s/it]
Current model: /mnt/data/yuliangyan/yuliangyan/meta-llama/Meta-Llama-3.1-8B-Instruct
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.3462, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.4683, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.5903, 0.4446, 0.2935, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.9468, 0.0000], dtype=torch.float16)
tensor([0.8184, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.1134, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.7871, 0.0000, 0.3767, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.6670, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.1129, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0663, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.2546, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.8647, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.7524, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.3528, 0.9351, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.8789, 0.2319, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([1., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.9326], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.5942], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.7021], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.7505, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.7993, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.8022, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.7402], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.2954], dtype=torch.float16)
tensor([0.3098, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.3811, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.5146], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.1675], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.7075, 0.2947, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.6460, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.7207, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.1238], dtype=torch.float16)
tensor([0.1711, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.9321, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.8765, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 1., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.1648, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.5337], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0568, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.8022], dtype=torch.float16)
tensor([0.5674, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.3936, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.3428, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.7148, 0.0000, 0.0000], dtype=torch.float16)
tensor([1.0000, 0.2964, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.8120, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.2742, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.1482, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.5884], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0858, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.4250, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.1199, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.8218], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.8120, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.5249], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.5898], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0608, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.8989, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.9385], dtype=torch.float16)
tensor([0.0000, 0.1656, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([1., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.9199, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.8066, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.7710, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([1., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.6157, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.4421, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 1.], dtype=torch.float16)
100
100
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.15s/it]
Processing files:   0%|          | 0/1 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Processing files: 100%|██████████| 1/1 [00:28<00:00, 28.53s/it]Processing files: 100%|██████████| 1/1 [00:28<00:00, 28.53s/it]
Current model: /mnt/data/haochuntang/mistralai/Mistral-7B-Instruct-v0.1
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.6602, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.4561, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.7070, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.1344, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.2242, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.4089, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.6411, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0853, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.4299, 0.0000], dtype=torch.float16)
tensor([0.1366, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.1064, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.5376, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.5796, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.1715], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.2839, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.1486], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.2849, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.4763], dtype=torch.float16)
tensor([0.0991, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.1782, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.3030, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 1.], dtype=torch.float16)
tensor([0., 0., 0., 1.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.1996, 0.0000], dtype=torch.float16)
tensor([0.1577, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.2235, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.5195, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.8149, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.8042, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.8135, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0794, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.8306, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.6475, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.3284, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.2766, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.8345, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.1687, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.3997, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.4001, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.1843], dtype=torch.float16)
tensor([0.2040, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.1390], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.5586, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.0503], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.1207, 0.0000], dtype=torch.float16)
tensor([0.4949, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.3354, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.3621], dtype=torch.float16)
tensor([0.0000, 0.5537, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.6572, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 1., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.4084, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.5005, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.5957], dtype=torch.float16)
tensor([0.3755, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.3025], dtype=torch.float16)
100
100
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.02s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.08s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:06<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.04s/it]
Processing files:   0%|          | 0/1 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Processing files: 100%|██████████| 1/1 [08:00<00:00, 480.74s/it]Processing files: 100%|██████████| 1/1 [08:00<00:00, 480.74s/it]
Current model: /mnt/data/yuliangyan/yuliangyan/Qwen/Qwen2.5-7B
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.1696, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.2898, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0833, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.2627, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.4138, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.4490, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.5771, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.3083], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0590, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.2377, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.6079, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.4106, 0.0000, 0.0000], dtype=torch.float16)
tensor([0.6211, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.1986], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.2605, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.1355, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.0634], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0580, 0.0000], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.5278, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 1., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.4482, 0.0000, 0.0000, 0.3564], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.2455], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.5522, 0.0000, 1.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 1., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0844, 0.8823, 0.4717, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.2559], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0469, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
100
100
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]
Processing files:   0%|          | 0/1 [00:00<?, ?it/s]The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Processing files: 100%|██████████| 1/1 [04:16<00:00, 256.67s/it]Processing files: 100%|██████████| 1/1 [04:16<00:00, 256.67s/it]
Current model: /mnt/data/haochuntang/google/gemma-2-2b-it
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0803, 1.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.5142, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([1., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0617, 0.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.0000, 0.0309], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0370, 1.0000, 1.0000, 1.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.0000, 0.4070, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0724, 1.0000, 1.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0000, 0.2333, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0.0454, 0.8623, 1.0000, 1.0000], dtype=torch.float16)
tensor([0.1597, 1.0000, 0.0000, 0.0000], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
tensor([0., 0., 0., 0.], dtype=torch.float16)
100
100
